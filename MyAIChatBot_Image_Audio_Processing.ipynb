{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d661ad5c-b074-45b6-98a8-c6a5a6033f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave, struct, os\n",
    "from openai import OpenAI\n",
    "from pvrecorder import PvRecorder\n",
    "from playsound import playsound\n",
    "from IPython.display import Image, display\n",
    "\n",
    " # silence deprecation warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e1d37c1-7830-41d1-8981-e407d1a9aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc5d3b63-c69b-4085-86f9-99f9fa2d3dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.context = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a witty assistant, always answering with a Joke.\"},\n",
    "        ]\n",
    "\n",
    "    def chat(self, message):\n",
    "        self.context.append(\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        )\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4-0125-preview\",\n",
    "            messages=self.context\n",
    "        )\n",
    "        response_content = response.choices[0].message.content\n",
    "        self.context.append(\n",
    "            {\"role\": \"assistant\", \"content\": response_content}\n",
    "        )\n",
    "        self.show_face(response_content)\n",
    "        self.print_chat()\n",
    "        self.speak(response_content)\n",
    "\n",
    "    def speak(self, message, index=0):\n",
    "        speech_file_path = os.getcwd() + f\"/speech_{index}.mp3\"\n",
    "        response = client.audio.speech.create(\n",
    "            model=\"tts-1-hd\",\n",
    "            voice=\"echo\",\n",
    "            input=message\n",
    "        )\n",
    "        response.stream_to_file(speech_file_path)\n",
    "        playsound(speech_file_path)\n",
    "\n",
    "    def record_audio(self, index=0):\n",
    "        recorder = PvRecorder(device_index=-1, frame_length=512)\n",
    "        audio = []\n",
    "        filepath = os.getcwd() + f\"/recorded_{index}.mp3\"\n",
    "        \n",
    "        try:\n",
    "            recorder.start()\n",
    "            print(\"Audio recording started ...\")\n",
    "            while True:\n",
    "                frame = recorder.read()\n",
    "                audio.extend(frame)\n",
    "        except KeyboardInterrupt:\n",
    "            recorder.stop()\n",
    "            print(\"Audio recording stopped ...\")\n",
    "            with wave.open(filepath, 'w') as f:\n",
    "                f.setparams((1, 2, 16000, 512, \"NONE\", \"NONE\"))\n",
    "                f.writeframes(struct.pack(\"h\" * len(audio), *audio))\n",
    "        finally:\n",
    "            recorder.delete()\n",
    "            return filepath\n",
    "\n",
    "    def transcribe(self, audio_path):\n",
    "        audio_file= open(audio_path, \"rb\")\n",
    "        transcript = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\", \n",
    "            file=audio_file\n",
    "        )\n",
    "        return transcript.text \n",
    "\n",
    "    def voicechat(self):\n",
    "        recorded_filepath = self.record_audio(index=len(self.context))\n",
    "        message = self.transcribe(recorded_filepath)\n",
    "        self.chat(message)\n",
    "\n",
    "    def show_face(self, message):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4-0125-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"\n",
    "                    You are a face describing system which describes the face of a funny person making a funny comment.\n",
    "\t\t\t\t\t\tYou receive the text the person is saying, please describe the face that would be fitting as a prompt to the stable diffusion image generation AI, DALLÂ·E.\n",
    "                \"\"\"},\n",
    "                {\"role\": \"user\", \"content\": message},\n",
    "              ]\n",
    "        )\n",
    "        image_description = response.choices[0].message.content\n",
    "\n",
    "        response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=image_description,\n",
    "            size=\"1024x1024\",\n",
    "            quality=\"standard\",\n",
    "            n=1,\n",
    "        )\n",
    "        \n",
    "        display(Image(url=response.data[0].url))\n",
    "\n",
    "    def print_chat(self):\n",
    "        for message in self.context:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                print(f'USER: {message[\"content\"]}')\n",
    "            elif message[\"role\"] == \"assistant\":\n",
    "                print(f'BOT: {message[\"content\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc59fd56-eb0a-4624-9ca4-5aa2c717003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = Chatbot(client)\n"
   ]
  }
